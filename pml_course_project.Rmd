<<<<<<< HEAD
---
title: "PRACTICAL MACHINE LEARNING COURSE PROJECT"
author: "Vyjayanthi TUPURANI"
Date: "Friday, April 24, 2015"
Output: html_document
---

---
Background Of THIS pROJECT 
---
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

---
Data:
---
The training data for this project are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.

The goal of this project is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to create a report describing how the model was built, how the cross validation is used, and the expected sample error. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

To reproduce the same results,the following set of libraries from correcsponding packages are needed.Also a random number generator was taken (set.seed(1997))

The code is with variable is "classe", has 5 levels in which the participants were asked to perform one set of 10 repetetions of the Unilateral Dumbbell bicep curls in 5 ways as
Class A- according to specification
Class B- throwing elbow to front
Class C- lifting dumbell half way
Class D- lowering dumbbell only half way
Class E- throwing hips to the front
```{r}
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)

set.seed(1997)

```

Download the required training data and testing data:
```{r}
trainingData <- read.csv("C:/Users/Vyjayanthi/Desktop/Training.csv", na.strings=c("NA","#DIV/0!", ""))
testingData <- read.csv("C:/Users/Vyjayanthi/Desktop/Testing.csv", na.strings=c("NA","#DIV/0!", ""))
```

Check the dimensions of the data

```{r}
dim(trainingData)
dim(testingData)
 
```

Now delete the columns with missing values:
```{r}
trainingData <- trainingData[ , colSums(is.na(trainingData))==0]
testingData <- testingData[ , colSums(is.na(testingData))==0]
```

To delete irrelvent columns from the data,
```{r}
trainingData <- trainingData[ , -c(1:7)]
testingData <- testingData[ , -c(1:7)]
head(trainingData)
head(testingData)
 
```

Cross Validation:
To perform cross validation, the large sample trianing data set is divided into 2 sets.

```{r}
subSamples <- createDataPartition(y=trainingData$classe, p=0.75, list =FALSE)
subTraining <- trainingData[subSamples,]
subTesting <- trainingData[-subSamples, ]
dim(subTraining)
dim(subTesting)
```

Since this variable "Classe" contains 5 levels, and a plot of the outcome variable helps us to see the frequency of each level in the data for comparison.

```{r}
plot(subTraining$classe, col ="pink", main= "Levels of Variable Classe within the Training data set",
     xlab="Class Levels", 
     ylab= "Frequency")

#From the graph, level A has the greatest frequency.
```

Prediction using decision tree,
```{r}
model1 <- rpart(classe ~., data = subTraining, method ="class")
prediction1 <- predict(model1, subTesting, type= "class")
rpart.plot(model1, main= "Decision Tree", extra= 102, under=TRUE, faclen=0)

confusionMatrix(prediction1, subTesting$classe)
```

Prediction using Random Forest:
```{r}
model2 <- randomForest(classe ~., data = subTraining, method ="class")
prediction2 <- predict(model2, subTesting, type = "class")
confusionMatrix (prediction2, subTesting$classe)
```

From these two predictions, random forest algorithm has better accurate results. The accuracy is 0.995 and the expected out of sample error is 0.005. The expected out of sample sample error came out to 1, with this 99% accuracy, it is expected that very few of test samples were missing.


---
Submission
---

Using random forest, predictions of outcome levels of original testingdata

```{r}
predictFinal <- predict( model2, testingData, type ="class")
predictFinal
```
=======
>>>>>>> f15fd41e9a1a90445a58f1cae1da480cf6c140a6

